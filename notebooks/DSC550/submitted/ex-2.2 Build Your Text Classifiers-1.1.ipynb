{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing Text: For this part, you will start by reading the controversial-comments.jsonl file into a DataFrame. Then,\n",
    "\n",
    "A. Convert all text to lowercase letters.\n",
    "\n",
    "B. Remove all punctuation from the text.\n",
    "\n",
    "C. Remove stop words.\n",
    "\n",
    "D. Apply NLTK’s PorterStemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the json lines file into a dataframe\n",
    "df_comments = pd.read_json('controversial-comments.jsonl', lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Well it's great that he did something about th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You are right Mr. President.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>You have given no input apart from saying I am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>I get the frustration but the reason they want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I am far from an expert on TPP and I would ten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   con                                                txt\n",
       "0    0  Well it's great that he did something about th...\n",
       "1    0                       You are right Mr. President.\n",
       "2    0  You have given no input apart from saying I am...\n",
       "3    0  I get the frustration but the reason they want...\n",
       "4    0  I am far from an expert on TPP and I would ten..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the dataframe to see how the data gets loaded.\n",
    "df_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 950000 entries, 0 to 949999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   con     950000 non-null  int64 \n",
      " 1   txt     950000 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 14.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Viewing the info on the dataframe\n",
    "df_comments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of the sample dataframe\n",
    "df_sample = df_comments.sample(n=50000)\n",
    "df_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using string from the conversion and remove all punctuations \n",
    "import unicodedata\n",
    "import sys\n",
    "\n",
    "# Create a dictionary of punctuation characters\n",
    "punctuation = dict.fromkeys(i for i in range(sys.maxunicode)\n",
    "                           if unicodedata.category(chr(i)).startswith('P'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the array of stop words from the nltk package\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Load the stop words\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view some stop words from the array\n",
    "stop_words[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using NLTK’s PorterStemmer\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "# Create stemmer\n",
    "porter = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This shows how stemmer breaks down words to its stem values.\n",
    "# porter.stem('jumps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created a function in order to perform preprocessing on the text value passed as a series\n",
    "# All of the 4 tasks that was given in the Exercise 1 are done in here\n",
    "# I also added a few more preprocessing tasks after the D\n",
    "def preprocess_txt(input_txt):\n",
    "    preprocessed_text = input_txt\n",
    "    # A. Convert all text to lowercase letters.\n",
    "    preprocessed_text = \" \".join(word.lower() for word in preprocessed_text.split())\n",
    "    # B. Remove all punctuation from the text.\n",
    "    preprocessed_text = \" \".join(word.translate(punctuation) for word in preprocessed_text.split())\n",
    "    # C. Remove stop words.\n",
    "    preprocessed_text = \" \".join(word for word in preprocessed_text.split() if word not in stop_words)\n",
    "    # D. Apply NLTK’s PorterStemmer.\n",
    "    preprocessed_text = \" \".join(porter.stem(word) for word in preprocessed_text.split())\n",
    "    return(preprocessed_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['processed_txt'] = df_sample['txt'].apply(lambda x: preprocess_txt(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following post processing is done on the processed text series\n",
    "# This is to further remove some texts with no space that do not make any contribution towards analysis\n",
    "\n",
    "df_sample['processed_txt'] = df_sample['processed_txt'].str.replace(r'\\[removed\\]',\"\")\n",
    "df_sample['processed_txt'] = df_sample['processed_txt'].str.replace(r'\\[deleted\\]',\"\")\n",
    "df_sample['processed_txt'] = df_sample['processed_txt'].str.replace(r'&.*;',\"\")\n",
    "df_sample['processed_txt'] = df_sample['processed_txt'].str.replace(r'\\[',\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['len_b4'] = df_sample['txt'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['len_aftr'] = df_sample['processed_txt'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 50000 entries, 400139 to 146752\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   con            50000 non-null  int64 \n",
      " 1   txt            50000 non-null  object\n",
      " 2   processed_txt  50000 non-null  object\n",
      " 3   len_b4         50000 non-null  int64 \n",
      " 4   len_aftr       50000 non-null  int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "      <th>processed_txt</th>\n",
       "      <th>len_b4</th>\n",
       "      <th>len_aftr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400139</th>\n",
       "      <td>0</td>\n",
       "      <td>Lets use military action to stop these people ...</td>\n",
       "      <td>Lets use military action to stop these people ...</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550836</th>\n",
       "      <td>0</td>\n",
       "      <td>I can't fathom why these women would make a sh...</td>\n",
       "      <td>I can't fathom why these women would make a sh...</td>\n",
       "      <td>361</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284328</th>\n",
       "      <td>0</td>\n",
       "      <td>Plus we heard the SJWs and the alt left folks ...</td>\n",
       "      <td>Plus we heard the SJWs and the alt left folks ...</td>\n",
       "      <td>242</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777068</th>\n",
       "      <td>0</td>\n",
       "      <td>Can some ELI5: how this can even be a discussi...</td>\n",
       "      <td>Can some ELI5: how this can even be a discussi...</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929858</th>\n",
       "      <td>0</td>\n",
       "      <td>[removed]</td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        con                                                txt  \\\n",
       "400139    0  Lets use military action to stop these people ...   \n",
       "550836    0  I can't fathom why these women would make a sh...   \n",
       "284328    0  Plus we heard the SJWs and the alt left folks ...   \n",
       "777068    0  Can some ELI5: how this can even be a discussi...   \n",
       "929858    0                                          [removed]   \n",
       "\n",
       "                                            processed_txt  len_b4  len_aftr  \n",
       "400139  Lets use military action to stop these people ...     144       144  \n",
       "550836  I can't fathom why these women would make a sh...     361       361  \n",
       "284328  Plus we heard the SJWs and the alt left folks ...     242       242  \n",
       "777068  Can some ELI5: how this can even be a discussi...      72        72  \n",
       "929858                                                          9         0  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 5)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out the rows from the data frame having zero length after the preprocessing\n",
    "fltr = df_sample['len_aftr']==0\n",
    "df_sample_fltr = df_sample.drop(index = df_sample[fltr].index) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45993, 5)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample_fltr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply each of the following steps (individually) to the pre-processed data.\n",
    "\n",
    "A. Convert each text entry into a word-count vector (see sections 5.3 & 6.8 in the Machine Learning with Python Cookbook).\n",
    "\n",
    "B. Convert each text entry into a part-of-speech tag vector (see section 6.7 in the Machine Learning with Python Cookbook).\n",
    "\n",
    "C. Convert each entry into a term frequency-inverse document frequency (tfidf) vector (see section 6.9 in the Machine Learning with Python Cookbook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This below implementation of the .values returns the values from the particular column as a numpy array\n",
    "# This could be now passed on as an array to generate bag of words\n",
    "# df_sample['processed_txt'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000000000001</th>\n",
       "      <th>0000001</th>\n",
       "      <th>000000606</th>\n",
       "      <th>00000156</th>\n",
       "      <th>00000158</th>\n",
       "      <th>0001</th>\n",
       "      <th>000217</th>\n",
       "      <th>00040</th>\n",
       "      <th>...</th>\n",
       "      <th>сороса</th>\n",
       "      <th>теперь</th>\n",
       "      <th>трампа</th>\n",
       "      <th>украине</th>\n",
       "      <th>феликс</th>\n",
       "      <th>эдмундович</th>\n",
       "      <th>этом</th>\n",
       "      <th>яepublican</th>\n",
       "      <th>яepublicans</th>\n",
       "      <th>ಠ_ಠ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45988</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45989</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45990</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45991</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45992</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45993 rows × 39789 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       00  000  000000000001  0000001  000000606  00000156  00000158  0001  \\\n",
       "0       0    0             0        0          0         0         0     0   \n",
       "1       0    0             0        0          0         0         0     0   \n",
       "2       0    0             0        0          0         0         0     0   \n",
       "3       0    0             0        0          0         0         0     0   \n",
       "4       0    0             0        0          0         0         0     0   \n",
       "...    ..  ...           ...      ...        ...       ...       ...   ...   \n",
       "45988   0    0             0        0          0         0         0     0   \n",
       "45989   0    0             0        0          0         0         0     0   \n",
       "45990   0    0             0        0          0         0         0     0   \n",
       "45991   0    0             0        0          0         0         0     0   \n",
       "45992   0    0             0        0          0         0         0     0   \n",
       "\n",
       "       000217  00040  ...  сороса  теперь  трампа  украине  феликс  \\\n",
       "0           0      0  ...       0       0       0        0       0   \n",
       "1           0      0  ...       0       0       0        0       0   \n",
       "2           0      0  ...       0       0       0        0       0   \n",
       "3           0      0  ...       0       0       0        0       0   \n",
       "4           0      0  ...       0       0       0        0       0   \n",
       "...       ...    ...  ...     ...     ...     ...      ...     ...   \n",
       "45988       0      0  ...       0       0       0        0       0   \n",
       "45989       0      0  ...       0       0       0        0       0   \n",
       "45990       0      0  ...       0       0       0        0       0   \n",
       "45991       0      0  ...       0       0       0        0       0   \n",
       "45992       0      0  ...       0       0       0        0       0   \n",
       "\n",
       "       эдмундович  этом  яepublican  яepublicans  ಠ_ಠ  \n",
       "0               0     0           0            0    0  \n",
       "1               0     0           0            0    0  \n",
       "2               0     0           0            0    0  \n",
       "3               0     0           0            0    0  \n",
       "4               0     0           0            0    0  \n",
       "...           ...   ...         ...          ...  ...  \n",
       "45988           0     0           0            0    0  \n",
       "45989           0     0           0            0    0  \n",
       "45990           0     0           0            0    0  \n",
       "45991           0     0           0            0    0  \n",
       "45992           0     0           0            0    0  \n",
       "\n",
       "[45993 rows x 39789 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A. Convert each text entry into a word-count vector.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create a bag of words feature matrix\n",
    "count = CountVectorizer()\n",
    "bag_of_words = count.fit_transform(df_sample_fltr['processed_txt'].values)\n",
    "\n",
    "# bag_of_words.toarray()\n",
    "\n",
    "words = count.get_feature_names()\n",
    "feature_matrix = pd.DataFrame(bag_of_words.toarray(),columns=words)\n",
    "feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992691001705665"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert dense to sparse\n",
    "# from scipy.sparse import csr_matrix\n",
    "# calculate sparcity\n",
    "# np.count_nonzero(feature_matrix)\n",
    "# feature_matrix.size\n",
    "# sparsity = 1 -  np.count_nonzero(feature_matrix)/feature_matrix.size\n",
    "# sparsity\n",
    "# convert to sparse matrix (CSR method)\n",
    "# feature_matrix_csr = csr_matrix(feature_matrix)\n",
    "# feature_matrix_csr.shape\n",
    "# reconstruct dense matrix\n",
    "# feature_matrix_dense = feature_matrix_csr.todense()\n",
    "# feature_matrix_dense.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str(df_sample['processed_txt'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. Convert each text entry into a part-of-speech tag vector\n",
    "# Using NLTK's pre trained parts of speech tagger\n",
    "\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Use the pre trained parts of speech tagger\n",
    "\n",
    "text_tagged = pos_tag(word_tokenize(str(df_sample_fltr['processed_txt'].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[', 'NN')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tagged[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000000000001</th>\n",
       "      <th>0000001</th>\n",
       "      <th>000000606</th>\n",
       "      <th>00000156</th>\n",
       "      <th>00000158</th>\n",
       "      <th>0001</th>\n",
       "      <th>000217</th>\n",
       "      <th>00040</th>\n",
       "      <th>...</th>\n",
       "      <th>сороса</th>\n",
       "      <th>теперь</th>\n",
       "      <th>трампа</th>\n",
       "      <th>украине</th>\n",
       "      <th>феликс</th>\n",
       "      <th>эдмундович</th>\n",
       "      <th>этом</th>\n",
       "      <th>яepublican</th>\n",
       "      <th>яepublicans</th>\n",
       "      <th>ಠ_ಠ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45988</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45989</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45990</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45991</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45992</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45993 rows × 39789 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        00  000  000000000001  0000001  000000606  00000156  00000158  0001  \\\n",
       "0      0.0  0.0           0.0      0.0        0.0       0.0       0.0   0.0   \n",
       "1      0.0  0.0           0.0      0.0        0.0       0.0       0.0   0.0   \n",
       "2      0.0  0.0           0.0      0.0        0.0       0.0       0.0   0.0   \n",
       "3      0.0  0.0           0.0      0.0        0.0       0.0       0.0   0.0   \n",
       "4      0.0  0.0           0.0      0.0        0.0       0.0       0.0   0.0   \n",
       "...    ...  ...           ...      ...        ...       ...       ...   ...   \n",
       "45988  0.0  0.0           0.0      0.0        0.0       0.0       0.0   0.0   \n",
       "45989  0.0  0.0           0.0      0.0        0.0       0.0       0.0   0.0   \n",
       "45990  0.0  0.0           0.0      0.0        0.0       0.0       0.0   0.0   \n",
       "45991  0.0  0.0           0.0      0.0        0.0       0.0       0.0   0.0   \n",
       "45992  0.0  0.0           0.0      0.0        0.0       0.0       0.0   0.0   \n",
       "\n",
       "       000217  00040  ...  сороса  теперь  трампа  украине  феликс  \\\n",
       "0         0.0    0.0  ...     0.0     0.0     0.0      0.0     0.0   \n",
       "1         0.0    0.0  ...     0.0     0.0     0.0      0.0     0.0   \n",
       "2         0.0    0.0  ...     0.0     0.0     0.0      0.0     0.0   \n",
       "3         0.0    0.0  ...     0.0     0.0     0.0      0.0     0.0   \n",
       "4         0.0    0.0  ...     0.0     0.0     0.0      0.0     0.0   \n",
       "...       ...    ...  ...     ...     ...     ...      ...     ...   \n",
       "45988     0.0    0.0  ...     0.0     0.0     0.0      0.0     0.0   \n",
       "45989     0.0    0.0  ...     0.0     0.0     0.0      0.0     0.0   \n",
       "45990     0.0    0.0  ...     0.0     0.0     0.0      0.0     0.0   \n",
       "45991     0.0    0.0  ...     0.0     0.0     0.0      0.0     0.0   \n",
       "45992     0.0    0.0  ...     0.0     0.0     0.0      0.0     0.0   \n",
       "\n",
       "       эдмундович  этом  яepublican  яepublicans  ಠ_ಠ  \n",
       "0             0.0   0.0         0.0          0.0  0.0  \n",
       "1             0.0   0.0         0.0          0.0  0.0  \n",
       "2             0.0   0.0         0.0          0.0  0.0  \n",
       "3             0.0   0.0         0.0          0.0  0.0  \n",
       "4             0.0   0.0         0.0          0.0  0.0  \n",
       "...           ...   ...         ...          ...  ...  \n",
       "45988         0.0   0.0         0.0          0.0  0.0  \n",
       "45989         0.0   0.0         0.0          0.0  0.0  \n",
       "45990         0.0   0.0         0.0          0.0  0.0  \n",
       "45991         0.0   0.0         0.0          0.0  0.0  \n",
       "45992         0.0   0.0         0.0          0.0  0.0  \n",
       "\n",
       "[45993 rows x 39789 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C. Convert each entry into a term frequency-inverse document frequency (tfidf) vector \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create the tf-idf feature matrix\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(df_sample_fltr['processed_txt'].values)\n",
    "\n",
    "# show the matrix\n",
    "# tfidf_matrix.toarray()\n",
    "\n",
    "words = tfidf.get_feature_names()\n",
    "tfidf_matrix = pd.DataFrame(tfidf_matrix.toarray(),columns=words)\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dense to sparse\n",
    "# calculate sparcity\n",
    "# np.count_nonzero(feature_matrix)\n",
    "# feature_matrix.size\n",
    "sparsity = 1 -  np.count_nonzero(tfidf_matrix)/tfidf_matrix.size\n",
    "sparsity\n",
    "# convert to sparse matrix (CSR method)\n",
    "tfidf_matrix_csr = csr_matrix(tfidf_matrix)\n",
    "# tfidf_matrix_csr.shape\n",
    "# reconstruct dense matrix\n",
    "tfidf_matrix_dense = tfidf_matrix_csr.todense()\n",
    "# tfidf_matrix_dense.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
