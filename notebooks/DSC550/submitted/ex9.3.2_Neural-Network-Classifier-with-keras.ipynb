{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitdd2052ddce364b29b70b9ef2f4771a5e",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "2. Neural Network Classifier with Keras\n",
    "Using the multi-label classifier dataset from earlier exercises (categorized-comments.jsonl in the reddit folder), fit a neural network classifier using Keras. Use the code found in chapter 12 of the Applied Text Analysis with Python book as a guideline. Report the accuracy, precision, recall, F1-score, and confusion matrix.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a multiclass Classifier\n",
    "# Using Keras to construct a feedforward neural network with an output layer with soft-max activation functions\n",
    "\n",
    "# Load libraries\n",
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "#import json library to read data in jsonl file\n",
    "import json\n",
    "#import pandas library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      cat                                                txt\n",
       "0  sports  Barely better than Gabbert? He was significant...\n",
       "1  sports  Fuck the ducks and the Angels! But welcome to ...\n",
       "2  sports  Should have drafted more WRs.\\n\\n- Matt Millen...\n",
       "3  sports            [Done](https://i.imgur.com/2YZ90pm.jpg)\n",
       "4  sports                                      No!! NOO!!!!!"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat</th>\n      <th>txt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sports</td>\n      <td>Barely better than Gabbert? He was significant...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sports</td>\n      <td>Fuck the ducks and the Angels! But welcome to ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sports</td>\n      <td>Should have drafted more WRs.\\n\\n- Matt Millen...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sports</td>\n      <td>[Done](https://i.imgur.com/2YZ90pm.jpg)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>sports</td>\n      <td>No!! NOO!!!!!</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "#read in the data as a dataframe\n",
    "filename = \"/home/arindam/Documents/mygithub/bu_dsc/data/raw/categorized-comments.jsonl\"\n",
    "with open(filename, 'r') as f:\n",
    "    jsonl_list = list(f)\n",
    "\n",
    "list1 = []\n",
    "for obj in jsonl_list:\n",
    "    res = json.loads(obj)\n",
    "    list1.append(res)\n",
    "    \n",
    "comments = pd.DataFrame(list1)\n",
    "\n",
    "#display the first few rows of data\n",
    "comments.head()\n",
    "# len(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert text to lowercase and romove punctuation\n",
    "#define a function to clean the text\n",
    "# import the required libraries here\n",
    "#import regular expressions library\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Remove punctuations and special characters, makes lower case\n",
    "    Args: text\n",
    "    Output: text\n",
    "    \"\"\"\n",
    "    text=text.lower() #makes text lowercase\n",
    "    text=re.sub('\\\\d|\\\\W+|_',' ',text) #removes extra white space\n",
    "    text=re.sub('[^a-zA-Z]',\" \", text) #removes any non-alphabetic characters\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                          cat  \\\n",
       "0                     sports   \n",
       "1                     sports   \n",
       "2                     sports   \n",
       "3                     sports   \n",
       "4                     sports   \n",
       "...                      ...   \n",
       "4995  science_and_technology   \n",
       "4996  science_and_technology   \n",
       "4997  science_and_technology   \n",
       "4998  science_and_technology   \n",
       "4999  science_and_technology   \n",
       "\n",
       "                                                    txt  \\\n",
       "0     Barely better than Gabbert? He was significant...   \n",
       "1     Fuck the ducks and the Angels! But welcome to ...   \n",
       "2     Should have drafted more WRs.\\n\\n- Matt Millen...   \n",
       "3               [Done](https://i.imgur.com/2YZ90pm.jpg)   \n",
       "4                                         No!! NOO!!!!!   \n",
       "...                                                 ...   \n",
       "4995  I just recently bought a tv with chromecast bu...   \n",
       "4996  SMS just works, is reliable. Everyone I know h...   \n",
       "4997                                          [deleted]   \n",
       "4998  It's not perfect, but certainly better than th...   \n",
       "4999  I have the same issue.  So if you're not using...   \n",
       "\n",
       "                                                cleaned  ncat  \n",
       "0     barely better than gabbert he was significantl...     1  \n",
       "1     fuck the ducks and the angels but welcome to a...     1  \n",
       "2     should have drafted more wrs matt millen probably     1  \n",
       "3                   done https i imgur com  yz  pm jpg      1  \n",
       "4                                               no noo      1  \n",
       "...                                                 ...   ...  \n",
       "4995  i just recently bought a tv with chromecast bu...     2  \n",
       "4996  sms just works is reliable everyone i know has...     2  \n",
       "4997                                           deleted      2  \n",
       "4998  it s not perfect but certainly better than the...     2  \n",
       "4999  i have the same issue so if you re not using t...     2  \n",
       "\n",
       "[5000 rows x 4 columns]>"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "# Cleaning texts in the comments\n",
    "# Using the transformed column for the model\n",
    "# Testing the functions\n",
    "\n",
    "sample_size = 5000\n",
    "sample_cmnts = comments[:sample_size]\n",
    "sample_cmnts['cleaned']=sample_cmnts['txt'].apply(clean_text)\n",
    "# creating a dictionary to replace the string values to numeric\n",
    "d = {'sports':1,'science_and_technology':2,'video_games':3}\n",
    "sample_cmnts['ncat'] = sample_cmnts['cat'].map(d)\n",
    "sample_cmnts.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1    3556\n",
       "2    1444\n",
       "Name: ncat, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "sample_cmnts.ncat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "output_activation=sample_cmnts.ncat.unique()[1]\n",
    "output_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the target name\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Creating the features from the data set\n",
    "features, target = sample_cmnts.cleaned, sample_cmnts.ncat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5000, 5000)"
      ]
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "number_of_features = 5000\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features = number_of_features, stop_words=stopwords.words('english'))\n",
    "\n",
    "features = tfidf.fit_transform(features).toarray()\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make test and training split (30:70)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train, y_test = train_test_split(features,target, random_state=0, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(35000,)"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "# X_train.shape\n",
    "# X_test.shape\n",
    "# y_train.shape\n",
    "# y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Neural Network\n",
    "network = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding fully connected input layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=100,\n",
    "                         activation='relu',\n",
    "                         input_shape=(number_of_features,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add fully connected layer with ReLU activation function\n",
    "network.add(layers.Dense(units=200, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add fully connected layer with a softmax activation function\n",
    "network.add(layers.Dense(units=output_activation-1, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile neural network\n",
    "network.compile(loss=\"categorical_crossentropy\", # Cross-entropy\n",
    "                optimizer=\"rmsprop\", # Root Mean Square Propagation\n",
    "                metrics=[\"accuracy\"]) # Accuracy performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/3\n",
      "35/35 [==============================] - 6s 178ms/step - loss: 0.0000e+00 - accuracy: 0.7194 - val_loss: 0.0000e+00 - val_accuracy: 0.6920\n",
      "Epoch 2/3\n",
      "35/35 [==============================] - 6s 179ms/step - loss: 0.0000e+00 - accuracy: 0.7194 - val_loss: 0.0000e+00 - val_accuracy: 0.6920\n",
      "Epoch 3/3\n",
      "35/35 [==============================] - 6s 163ms/step - loss: 0.0000e+00 - accuracy: 0.7194 - val_loss: 0.0000e+00 - val_accuracy: 0.6920\n"
     ]
    }
   ],
   "source": [
    "# Train neural network\n",
    "history = network.fit(X_train, # Features\n",
    "                      y_train, # Target\n",
    "                      epochs=3, # Three epochs\n",
    "                      verbose=1, # show output\n",
    "                      batch_size=100, # Number of observations per batch\n",
    "                      validation_data=(X_test, y_test)) # Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the Model\n",
    "\n",
    "model_path=\"/home/arindam/Documents/mygithub/bu_dsc/models\"\n",
    "model_name=\"NN_keras.h5\"\n",
    "filename = model_path + \"/\" + model_name \n",
    "# print(filename)\n",
    "network.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a saved model\n",
    "from keras.models import load_model\n",
    "NN_clf = load_model(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the test set for the classifier\n",
    "y_pred = NN_clf.predict(X_test)\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix\n================\n[[1038    0]\n [ 462    0]]\nClassification Report\n=====================================================\n              precision    recall  f1-score   support\n\n           1       0.69      1.00      0.82      1038\n           2       0.00      0.00      0.00       462\n\n    accuracy                           0.69      1500\n   macro avg       0.35      0.50      0.41      1500\nweighted avg       0.48      0.69      0.57      1500\n\nAccuracy Score\n=====\n0.692\n"
     ]
    }
   ],
   "source": [
    "# Displaying the result metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(\"================\")\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"Classification Report\")\n",
    "print(\"=====================================================\")\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"Accuracy Score\")\n",
    "print(\"=====\")\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}