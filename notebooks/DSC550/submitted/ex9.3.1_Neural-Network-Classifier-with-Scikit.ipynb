{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitdd2052ddce364b29b70b9ef2f4771a5e",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nUsing the multi-label classifier dataset from earlier exercises (categorized-comments.jsonl in the reddit folder), fit a neural network classifier using scikit-learn. Use the code found in chapter 12 of the Applied Text Analysis with Python book as a guideline. Report the accuracy, precision, recall, F1-score, and confusion matrix.\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "'''\n",
    "Using the multi-label classifier dataset from earlier exercises (categorized-comments.jsonl in the reddit folder), fit a neural network classifier using scikit-learn. Use the code found in chapter 12 of the Applied Text Analysis with Python book as a guideline. Report the accuracy, precision, recall, F1-score, and confusion matrix.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import json library to read data in jsonl file\n",
    "import json\n",
    "#import pandas library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pandas version: 1.2.4\n"
     ]
    }
   ],
   "source": [
    "#check versions of packages\n",
    "print('pandas version:', pd.__version__)\n",
    "# print('numpy version:', np.__version__)\n",
    "# print('scikit-learn version:', sklearn.__version__)\n",
    "# print('NLTK version:', nltk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      cat                                                txt\n",
       "0  sports  Barely better than Gabbert? He was significant...\n",
       "1  sports  Fuck the ducks and the Angels! But welcome to ...\n",
       "2  sports  Should have drafted more WRs.\\n\\n- Matt Millen...\n",
       "3  sports            [Done](https://i.imgur.com/2YZ90pm.jpg)\n",
       "4  sports                                      No!! NOO!!!!!"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat</th>\n      <th>txt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sports</td>\n      <td>Barely better than Gabbert? He was significant...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sports</td>\n      <td>Fuck the ducks and the Angels! But welcome to ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sports</td>\n      <td>Should have drafted more WRs.\\n\\n- Matt Millen...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sports</td>\n      <td>[Done](https://i.imgur.com/2YZ90pm.jpg)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>sports</td>\n      <td>No!! NOO!!!!!</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "#read in the data as a dataframe\n",
    "filename = \"/home/arindam/Documents/mygithub/bu_dsc/data/raw/categorized-comments.jsonl\"\n",
    "with open(filename, 'r') as f:\n",
    "    jsonl_list = list(f)\n",
    "\n",
    "list1 = []\n",
    "for obj in jsonl_list:\n",
    "    res = json.loads(obj)\n",
    "    list1.append(res)\n",
    "    \n",
    "comments = pd.DataFrame(list1)\n",
    "\n",
    "#display the first few rows of data\n",
    "comments.head()\n",
    "# len(list1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The dataframe has a dimension of: (606476, 2)\nIt has 606476 comments\n"
     ]
    }
   ],
   "source": [
    "# print the dimension of the dataframe\n",
    "print('The dataframe has a dimension of:',comments.shape)\n",
    "print('It has {} comments'.format(comments.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The target names are : ['sports' 'science_and_technology' 'video_games']\nThis shows that there are only 3 categories in the total dataset\n"
     ]
    }
   ],
   "source": [
    "print('The target names are :', comments['cat'].unique())\n",
    "print('This shows that there are only 3 categories in the total dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert text to lowercase and romove punctuation\n",
    "#define a function to clean the text\n",
    "# import the required libraries here\n",
    "#import regular expressions library\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Remove punctuations and special characters, makes lower case\n",
    "    Args: text\n",
    "    Output: text\n",
    "    \"\"\"\n",
    "    text=text.lower() #makes text lowercase\n",
    "    text=re.sub('\\\\d|\\\\W+|_',' ',text) #removes extra white space\n",
    "    text=re.sub('[^a-zA-Z]',\" \", text) #removes any non-alphabetic characters\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import word tokenizer from NLTK\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def tokenize_text(txt):\n",
    "    \"\"\"\n",
    "    Takes in a sentence, tokenizes the words into a list,\n",
    "    \"\"\"\n",
    "    stop_words = stopwords.words('english')\n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    tokens = tokenizer.tokenize(txt)\n",
    "    return [token for token in tokens if token not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply NLTK's PorterStemmer\n",
    "#define a function to stem the words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def porter_stem_text(token_list):\n",
    "\n",
    "    porter = PorterStemmer()\n",
    "    return (\" \".join (porter.stem(token) for token in token_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          cat                                                txt  ncat\n",
       "0      sports  Barely better than Gabbert? He was significant...     1\n",
       "1      sports  Fuck the ducks and the Angels! But welcome to ...     1\n",
       "2      sports  Should have drafted more WRs.\\n\\n- Matt Millen...     1\n",
       "3      sports            [Done](https://i.imgur.com/2YZ90pm.jpg)     1\n",
       "4      sports                                      No!! NOO!!!!!     1\n",
       "...       ...                                                ...   ...\n",
       "99995  sports             Fine\\n\\n*Binny is love, Binny is life*     1\n",
       "99996  sports    Oh come on, that's too early to waste a review.     1\n",
       "99997  sports  This is unbelievable. 95-5 on a turning wicket...     1\n",
       "99998  sports                 WHY NOT THEY PLAYED HIM IN GEELONG     1\n",
       "99999  sports  Go out to eagle farm or something. Get blind w...     1\n",
       "\n",
       "[100000 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat</th>\n      <th>txt</th>\n      <th>ncat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sports</td>\n      <td>Barely better than Gabbert? He was significant...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sports</td>\n      <td>Fuck the ducks and the Angels! But welcome to ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sports</td>\n      <td>Should have drafted more WRs.\\n\\n- Matt Millen...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sports</td>\n      <td>[Done](https://i.imgur.com/2YZ90pm.jpg)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>sports</td>\n      <td>No!! NOO!!!!!</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>99995</th>\n      <td>sports</td>\n      <td>Fine\\n\\n*Binny is love, Binny is life*</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>99996</th>\n      <td>sports</td>\n      <td>Oh come on, that's too early to waste a review.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>99997</th>\n      <td>sports</td>\n      <td>This is unbelievable. 95-5 on a turning wicket...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>99998</th>\n      <td>sports</td>\n      <td>WHY NOT THEY PLAYED HIM IN GEELONG</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>99999</th>\n      <td>sports</td>\n      <td>Go out to eagle farm or something. Get blind w...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>100000 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "# Testing the functions\n",
    "sample_cmnts = comments[:100000]\n",
    "# txt = \"barely than significantly especially is an the ? better surrounded.\"\n",
    "# sample_cmnts['cat'].unique()\n",
    "# creating a dictionary to replace the string values to numeric\n",
    "d = {'sports':1,'science_and_technology':2,'video_games':3}\n",
    "sample_cmnts['ncat'] = sample_cmnts['cat'].map(d)\n",
    "sample_cmnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          cat                                                txt  ncat  \\\n",
       "0      sports  Barely better than Gabbert? He was significant...     1   \n",
       "1      sports  Fuck the ducks and the Angels! But welcome to ...     1   \n",
       "2      sports  Should have drafted more WRs.\\n\\n- Matt Millen...     1   \n",
       "3      sports            [Done](https://i.imgur.com/2YZ90pm.jpg)     1   \n",
       "4      sports                                      No!! NOO!!!!!     1   \n",
       "...       ...                                                ...   ...   \n",
       "99995  sports             Fine\\n\\n*Binny is love, Binny is life*     1   \n",
       "99996  sports    Oh come on, that's too early to waste a review.     1   \n",
       "99997  sports  This is unbelievable. 95-5 on a turning wicket...     1   \n",
       "99998  sports                 WHY NOT THEY PLAYED HIM IN GEELONG     1   \n",
       "99999  sports  Go out to eagle farm or something. Get blind w...     1   \n",
       "\n",
       "                                                 cleaned  \\\n",
       "0      barely better than gabbert he was significantl...   \n",
       "1      fuck the ducks and the angels but welcome to a...   \n",
       "2      should have drafted more wrs matt millen probably   \n",
       "3                    done https i imgur com  yz  pm jpg    \n",
       "4                                                no noo    \n",
       "...                                                  ...   \n",
       "99995                  fine binny is love binny is life    \n",
       "99996     oh come on that s too early to waste a review    \n",
       "99997  this is unbelievable      on a turning wicket ...   \n",
       "99998                 why not they played him in geelong   \n",
       "99999  go out to eagle farm or something get blind wa...   \n",
       "\n",
       "                                               tokenized  \\\n",
       "0      [barely, better, gabbert, significantly, bette...   \n",
       "1      [fuck, ducks, angels, welcome, new, niners, fans]   \n",
       "2                 [drafted, wrs, matt, millen, probably]   \n",
       "3                 [done, https, imgur, com, yz, pm, jpg]   \n",
       "4                                                  [noo]   \n",
       "...                                                  ...   \n",
       "99995                   [fine, binny, love, binny, life]   \n",
       "99996                   [oh, come, early, waste, review]   \n",
       "99997  [unbelievable, turning, wicket, aussie, tails,...   \n",
       "99998                                  [played, geelong]   \n",
       "99999  [go, eagle, farm, something, get, blind, watch...   \n",
       "\n",
       "                                                 stemmed  \n",
       "0      bare better gabbert significantli better year ...  \n",
       "1                   fuck duck angel welcom new niner fan  \n",
       "2                           draft wr matt millen probabl  \n",
       "3                          done http imgur com yz pm jpg  \n",
       "4                                                    noo  \n",
       "...                                                  ...  \n",
       "99995                         fine binni love binni life  \n",
       "99996                          oh come earli wast review  \n",
       "99997  unbeliev turn wicket aussi tail far hire fuck ...  \n",
       "99998                                       play geelong  \n",
       "99999           go eagl farm someth get blind watch race  \n",
       "\n",
       "[100000 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat</th>\n      <th>txt</th>\n      <th>ncat</th>\n      <th>cleaned</th>\n      <th>tokenized</th>\n      <th>stemmed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sports</td>\n      <td>Barely better than Gabbert? He was significant...</td>\n      <td>1</td>\n      <td>barely better than gabbert he was significantl...</td>\n      <td>[barely, better, gabbert, significantly, bette...</td>\n      <td>bare better gabbert significantli better year ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sports</td>\n      <td>Fuck the ducks and the Angels! But welcome to ...</td>\n      <td>1</td>\n      <td>fuck the ducks and the angels but welcome to a...</td>\n      <td>[fuck, ducks, angels, welcome, new, niners, fans]</td>\n      <td>fuck duck angel welcom new niner fan</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sports</td>\n      <td>Should have drafted more WRs.\\n\\n- Matt Millen...</td>\n      <td>1</td>\n      <td>should have drafted more wrs matt millen probably</td>\n      <td>[drafted, wrs, matt, millen, probably]</td>\n      <td>draft wr matt millen probabl</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sports</td>\n      <td>[Done](https://i.imgur.com/2YZ90pm.jpg)</td>\n      <td>1</td>\n      <td>done https i imgur com  yz  pm jpg</td>\n      <td>[done, https, imgur, com, yz, pm, jpg]</td>\n      <td>done http imgur com yz pm jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>sports</td>\n      <td>No!! NOO!!!!!</td>\n      <td>1</td>\n      <td>no noo</td>\n      <td>[noo]</td>\n      <td>noo</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>99995</th>\n      <td>sports</td>\n      <td>Fine\\n\\n*Binny is love, Binny is life*</td>\n      <td>1</td>\n      <td>fine binny is love binny is life</td>\n      <td>[fine, binny, love, binny, life]</td>\n      <td>fine binni love binni life</td>\n    </tr>\n    <tr>\n      <th>99996</th>\n      <td>sports</td>\n      <td>Oh come on, that's too early to waste a review.</td>\n      <td>1</td>\n      <td>oh come on that s too early to waste a review</td>\n      <td>[oh, come, early, waste, review]</td>\n      <td>oh come earli wast review</td>\n    </tr>\n    <tr>\n      <th>99997</th>\n      <td>sports</td>\n      <td>This is unbelievable. 95-5 on a turning wicket...</td>\n      <td>1</td>\n      <td>this is unbelievable      on a turning wicket ...</td>\n      <td>[unbelievable, turning, wicket, aussie, tails,...</td>\n      <td>unbeliev turn wicket aussi tail far hire fuck ...</td>\n    </tr>\n    <tr>\n      <th>99998</th>\n      <td>sports</td>\n      <td>WHY NOT THEY PLAYED HIM IN GEELONG</td>\n      <td>1</td>\n      <td>why not they played him in geelong</td>\n      <td>[played, geelong]</td>\n      <td>play geelong</td>\n    </tr>\n    <tr>\n      <th>99999</th>\n      <td>sports</td>\n      <td>Go out to eagle farm or something. Get blind w...</td>\n      <td>1</td>\n      <td>go out to eagle farm or something get blind wa...</td>\n      <td>[go, eagle, farm, something, get, blind, watch...</td>\n      <td>go eagl farm someth get blind watch race</td>\n    </tr>\n  </tbody>\n</table>\n<p>100000 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "# Cleaning and tokenizing the texts in the comments\n",
    "# Using the transformed column for the model\n",
    "\n",
    "sample_cmnts['cleaned']=sample_cmnts['txt'].apply(clean_text)\n",
    "sample_cmnts['tokenized']=sample_cmnts['cleaned'].apply(tokenize_text)\n",
    "sample_cmnts['stemmed']=sample_cmnts['tokenized'].apply(porter_stem_text)\n",
    "sample_cmnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                cat                                                txt  ncat\n",
       "0            sports  Barely better than Gabbert? He was significant...     1\n",
       "1            sports  Fuck the ducks and the Angels! But welcome to ...     1\n",
       "2            sports  Should have drafted more WRs.\\n\\n- Matt Millen...     1\n",
       "3            sports            [Done](https://i.imgur.com/2YZ90pm.jpg)     1\n",
       "4            sports                                      No!! NOO!!!!!     1\n",
       "...             ...                                                ...   ...\n",
       "606471  video_games             No. It's probably only happened to you     3\n",
       "606472  video_games  I think most of the disappointment came from t...     3\n",
       "606473  video_games  dishonored 1/2 looked like arse, so what the h...     3\n",
       "606474  video_games                                          [removed]     3\n",
       "606475  video_games  I wish more games provided options like Rise o...     3\n",
       "\n",
       "[606476 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat</th>\n      <th>txt</th>\n      <th>ncat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sports</td>\n      <td>Barely better than Gabbert? He was significant...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sports</td>\n      <td>Fuck the ducks and the Angels! But welcome to ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sports</td>\n      <td>Should have drafted more WRs.\\n\\n- Matt Millen...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sports</td>\n      <td>[Done](https://i.imgur.com/2YZ90pm.jpg)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>sports</td>\n      <td>No!! NOO!!!!!</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>606471</th>\n      <td>video_games</td>\n      <td>No. It's probably only happened to you</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>606472</th>\n      <td>video_games</td>\n      <td>I think most of the disappointment came from t...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>606473</th>\n      <td>video_games</td>\n      <td>dishonored 1/2 looked like arse, so what the h...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>606474</th>\n      <td>video_games</td>\n      <td>[removed]</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>606475</th>\n      <td>video_games</td>\n      <td>I wish more games provided options like Rise o...</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>606476 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "comments['cat'].unique()\n",
    "# creating a dictionary to replace the string values to numeric\n",
    "d = {'sports':1,'science_and_technology':2,'video_games':3}\n",
    "comments['ncat'] = comments['cat'].map(d)\n",
    "comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the target name\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Creating the features from the data set\n",
    "features, target = sample_cmnts.stemmed, sample_cmnts.ncat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Features-Training Set:  80000\nFeatures-Test Set:  20000\nTarget: Training Set:  80000\nTarget: Test Set:  20000\n"
     ]
    }
   ],
   "source": [
    "# Make test and training split (20:80)\n",
    "features_train,features_test,target_train, target_test = train_test_split(features,target, random_state=0, test_size = 0.2)\n",
    "\n",
    "print('Features-Training Set: ',len(features_train))\n",
    "print('Features-Test Set: ',len(features_test))\n",
    "print('Target: Training Set: ',len(target_train))\n",
    "print('Target: Test Set: ',len(target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.feature_extraction.text import TfidfTransformer\\nfrom sklearn.neural_network import MLPRegressor, MLPClassifier\\nfrom sklearn.feature_extraction.text import CountVectorizer\\n\\nclassifier = Pipeline([('vect', CountVectorizer()),\\n                       ('tfidf', TfidfTransformer()),\\n                       ('ann', MLPClassifier(hidden_layer_sizes=[500,150], verbose=True))\\n])\\nclf = classifier.fit(features_train, target_train)\\n\""
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "classifier = Pipeline([('vect', CountVectorizer()),\n",
    "                       ('tfidf', TfidfTransformer()),\n",
    "                       ('ann', MLPClassifier(hidden_layer_sizes=[500,150], verbose=True))\n",
    "])\n",
    "clf = classifier.fit(features_train, target_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "classifier = Pipeline([('vect', CountVectorizer()),\n",
    "                       ('tfidf', TfidfTransformer()),\n",
    "                       ('ann', MLPClassifier(hidden_layer_sizes=[500,150,100],  max_iter=50, activation='relu',solver='adam',verbose=False))\n",
    "])\n",
    "clf = classifier.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the Model\n",
    "\n",
    "import joblib\n",
    "from joblib import dump, load\n",
    "\n",
    "model_path=\"/home/arindam/Documents/mygithub/bu_dsc/models\"\n",
    "model_name=\"NN_classifier_sklearn.pkl\"\n",
    "filename = model_path + \"/\" + model_name \n",
    "# print(filename)\n",
    "joblib.dump(clf, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'filename' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e815bd768969>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load a saved model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mNN_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNN_clf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filename' is not defined"
     ]
    }
   ],
   "source": [
    "# Load a saved model\n",
    "\n",
    "NN_clf = open(filename,'rb')\n",
    "\n",
    "clf1 = joblib.load(NN_clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the test set for the classifier\n",
    "y_pred = clf1.predict(features_test)\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the result metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(\"================\")\n",
    "print(confusion_matrix(target_test,y_pred))\n",
    "print(\"Classification Report\")\n",
    "print(\"=====================================================\")\n",
    "\n",
    "print(classification_report(target_test,y_pred))\n",
    "print(\"Accuracy Score\")\n",
    "print(\"=====\")\n",
    "\n",
    "print(accuracy_score(target_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}