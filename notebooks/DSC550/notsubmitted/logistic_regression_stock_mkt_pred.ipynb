{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitbaseconda9c4f9ef913ec46fba5f8aa62969238f5",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = yf.download(\"^GSPC\",start='2001-01-03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data['Adj Close'].pct_change() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(\"Today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,6):\n",
    "    df['Lag '+str(i)] = df['Today'].shift(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Volume'] = data.Volume.shift(1).values/1_000_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Direction'] = [1 if i > 0 else 0 for i in df['Today']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the stats model we are adding a constant to the dataset\n",
    "# This is required as otherwise the model does not have an intercept\n",
    "df = sm.add_constant(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independant variable\n",
    "# The logistic regression model is using the Independant variables to predict the dependent varaible\n",
    "# The dependent variable is the Direction\n",
    "\n",
    "X = df[['const','Lag 1','Lag 2','Lag 3','Lag 4','Lag 5','Volume']]\n",
    "y = df['Direction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining our model\n",
    "# Before running the model need to make sure that no values are NaN\n",
    "model = sm.Logit(y,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now fitting the model to those variables\n",
    "result = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of the logistic regression\n",
    "# As per the summary the lowest P value is for the Lag 1\n",
    "result.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making prediction with the model\n",
    "prediction = result.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In logistic regression we need to get a binary output\n",
    "# So if the prediction > 0.5 then 1 else 0\n",
    "# Creating a confusion matrix that compares the actual values to the predicted values\n",
    "def confusion_matrix(act,pred):\n",
    "    predtrans = ['Up' if i > 0.5 else 'Down' for i in pred]\n",
    "    actuals = ['Up' if i > 0 else 'Down' for i in act]\n",
    "    confusion_matrix = pd.crosstab(pd.Series(actuals),\n",
    "                                    pd.Series(predtrans),\n",
    "                                    rownames=['Actual'],\n",
    "                                    colnames=['Predicted'])\n",
    "    return confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding out how many times the model has predicted correctly\n",
    "# Adding the diagonal values and dividing by the total observations\n",
    "# This model is overly optimistic as it was trained and tested on the same set of data.\n",
    "(197+2582)/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So now we are splitting the data into train and test data set\n",
    "# The train dataset contains data upto 2019\n",
    "# The test dataset is for the 2020 and up\n",
    "x_train = df[df.Date.dt.year < 2020][['const','Lag 1','Lag 2','Lag 3','Lag 4','Lag 5','Volume']]\n",
    "y_train = df[df.Date.dt.year < 2020]['Direction']\n",
    "\n",
    "x_test = df[df.Date.dt.year >= 2020][['const','Lag 1','Lag 2','Lag 3','Lag 4','Lag 5','Volume']]\n",
    "y_test = df[df.Date.dt.year >= 2020]['Direction']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the model and provide the training data in order to train the model\n",
    "\n",
    "model = sm.Logit(y_train,x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now fitting the model to the training data\n",
    "result = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction on the Test data\n",
    "prediction = result.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the confusion matrix and passing the actual variables and the prediction\n",
    "confusion_matrix(y_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of observation is\n",
    "(13+173)/len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So now we are splitting the data into train and test data set\n",
    "# The train dataset contains data upto 2019\n",
    "# The test dataset is for the 2020 and up\n",
    "x_train = df[df.Date.dt.year < 2020][['const','Lag 1','Lag 2']]\n",
    "y_train = df[df.Date.dt.year < 2020]['Direction']\n",
    "\n",
    "x_test = df[df.Date.dt.year >= 2020][['const','Lag 1','Lag 2']]\n",
    "y_test = df[df.Date.dt.year >= 2020]['Direction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Logit(y_train,x_train)\n",
    "result = model.fit()\n",
    "prediction = result.predict(x_test)\n",
    "confusion_matrix(y_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(20+170)/len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}